
q: how do constraints_val get its dimensions
a: inequality: horizon * (num_env + state_dim + control_dim)
    + equality: horizon * (state_dim)
there is a discrepancy of 2

solver:: lifted trajectory game solver 
  - trajectory_reference_generators = neural networks
  - trajectory_optimizers = (problem, trajectory_solver)
    problem = parametric_trajectory_opt_problem
      
  - compose_reference_generator_input = (a,b,c)->[b;c]


initial_state = x0
context_state = []